% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/estimate_nhmm.R
\name{estimate_nhmm}
\alias{estimate_nhmm}
\title{Build and Estimate a Non-homogeneous Hidden Markov Model}
\usage{
estimate_nhmm(
  observations,
  n_states,
  initial_formula = ~1,
  transition_formula = ~1,
  emission_formula = ~1,
  data = NULL,
  time = NULL,
  id = NULL,
  state_names = NULL,
  channel_names = NULL,
  inits = "random",
  init_sd = 2,
  restarts = 0L,
  lambda = 0,
  method = "EM",
  pseudocount = 1e-04,
  store_data = TRUE,
  ...
)
}
\arguments{
\item{observations}{Either the name of the response variable in \code{data}, or
an \code{stslist} object (see \code{\link[TraMineR:seqdef]{TraMineR::seqdef()}}) containing the
sequences. In case of multichannel data, \code{observations} should be a vector
of response variable names in \code{data}, or a list of \code{stslist} objects.}

\item{n_states}{A positive integer defining the number of hidden states.}

\item{initial_formula}{of class \code{\link[=formula]{formula()}} for the
initial state probabilities.}

\item{transition_formula}{of class \code{\link[=formula]{formula()}} for the
state transition probabilities.}

\item{emission_formula}{of class \code{\link[=formula]{formula()}} for the
state emission probabilities.}

\item{data}{A data frame containing the variables used in the model
formulas. Can be omitted in case of model with no covariates and observations
given as \code{stslist} objects.}

\item{time}{Name of the time index variable in \code{data}.}

\item{id}{Name of the id variable in \code{data} identifying different
sequences.}

\item{state_names}{A vector of optional labels for the hidden states. If this
is \code{NULL} (the default), numbered states are used.}

\item{channel_names}{A vector of optional names for the channels. If this
is \code{NULL} (the default), numbered channels are used.}

\item{inits}{If \code{inits = "random"} (default), random initial values are
used. Otherwise \code{inits} should be list of initial values. If coefficients
are given using list components \code{eta_pi}, \code{eta_A}, \code{eta_B},
these are used as is, alternatively initial values can be given in terms of
the initial state, transition, and emission probabilities using list
components \code{initial_probs}, \code{emission_probs}, and \code{transition_probs}. These
can also be mixed, i.e. you can give only \code{initial_probs} and \code{eta_A}.}

\item{init_sd}{Standard deviation of the normal distribution used to generate
random initial values. Default is \code{2}. If you want to fix the initial values
of the regression coefficients to zero, use \code{init_sd = 0}.}

\item{restarts}{Number of times to run optimization using random starting
values (in addition to the final run). Default is 0.}

\item{lambda}{Penalization factor \code{lambda} for penalized log-likelihood, where the
penalization is \code{0.5 * lambda * sum(parameters^2)}. Note that with
\code{method = "L-BFGS"} both objective function (log-likelihood) and
the penalization term is scaled with number of non-missing observations.}

\item{method}{Optimization method used. Default is \code{"EM"} which uses EM
algorithm with L-BFGS in the M-step. Another option is \code{"LBFGS"} which uses
only L-BFGS for direct maximization of the log-likelihood.}

\item{pseudocount}{A positive scalar to be added for the expected counts of
E-step. Only used in EM algorithm. Default is 1e-4. Larger values can be used
to avoid zero probabilities in initial, transition, and emission
probabilities, i.e. these have similar role as \code{lambda}.}

\item{store_data}{If \code{TRUE} (default), original data frame passed as \code{data}
is stored to the model object. For large datasets, this can be set to
\code{FALSE}, in which case you might need to pass the data separately to some
post-prosessing functions.}

\item{...}{Additional arguments to \code{\link[nloptr:nloptr]{nloptr::nloptr()}}. Most importantly,
argument \code{maxeval} defines the maximum number of iterations for optimization.
The default is \code{1000} for restarts and \code{10000} for the final optimization.
Other useful arguments are \code{algorithm} (default uses LBFGS),
\code{print_level} (default is \code{0}, no console output of optimization), and
arguments for adjusting the stopping criteria of the optimization
(see details).}
}
\value{
Object of class \code{nhmm}.
}
\description{
Function \code{estimate_nhmm} estimates a hidden Markov model object of class
\code{nhmm} where initial, transition and emission probabilities
(potentially) depend on covariates.
}
\details{
By default, the model parameters are estimated using LBFGS algorithm of
\code{\link[nloptr:nloptr]{nloptr::nloptr()}}. The log-likelihood is
scaled by the number of non-missing observations (\code{nobs(model)}), and the
convergence is claimed when either the absolute or relative change of this
objective function is less than \code{1e-8}, or the absolute change of the
parameters is less than \code{1e-8}. The covariate data is standardardized before
optimization.

With multiple runs of optimization (by using the \code{restarts} argument), it is
possible to parallelize these runs using the \code{future} package, e.g., by
calling \code{future::plan(multisession, workers = 2)} before \code{estimate_nhmm()}.
See \code{\link[future:plan]{future::plan()}} for details. This is compatible with \code{progressr}
package, so you can use \code{\link[progressr:with_progress]{progressr::with_progress()}} to track the progress
of these multiple runs.
}
\examples{
data("mvad", package = "TraMineR")

d <- reshape(mvad, direction = "long", varying = list(15:86), 
  v.names = "activity")

\dontrun{
set.seed(1)
fit <- estimate_nhmm("activity", n_states = 3,
  data = d, time = "time", id = "id", 
  initial_formula = ~ 1, emission_formula =  ~ male + gcse5eq,
  transition_formula = ~ male + gcse5eq, inits = "random"
  )
}
}
